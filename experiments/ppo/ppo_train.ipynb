{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/group1/z44383r/dev/rl-nlg/experiments/ppo\n"
     ]
    }
   ],
   "source": [
    "%cd ppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_utils.path import ROOT_DPATH\n",
    "from common_utils.random_seed import set_seed\n",
    "from common_utils.multiwoz_data import MultiWOZData\n",
    "from sys_nlg.gpt2.model import build_gpt2\n",
    "from sys_nlg.gpt2.nlg import GPT2NLG\n",
    "\n",
    "from ppo_utils.ppo_updator import PPOUpdator, Rollouts\n",
    "from ppo_utils.ppo_train_data import PPOTrainData, ActionIDF\n",
    "from ppo_utils.reward import da_accuracy, ComputeReward\n",
    "\n",
    "from experiments.speech_error_simulation.error_simulator import SpeechErrorSimulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_dname = \"checkpoints\"\n",
    "lm_name = \"act_resp.4\"\n",
    "\n",
    "config = {\n",
    "    \"checkpoints_dname\": checkpoints_dname,\n",
    "    \"lm_name\": lm_name,\n",
    "    \"gpt2_config\": {\n",
    "        \"pretrained_model_dpath\": os.path.join(ROOT_DPATH, \"sys_nlg/gpt2/outputs\", checkpoints_dname, lm_name),\n",
    "        \"ref_model_dpath\": os.path.join(ROOT_DPATH, \"sys_nlg/gpt2/outputs\",  checkpoints_dname, lm_name),\n",
    "        \"tokenizer_name\": \"gpt2\",\n",
    "        \"lm_task_type\": os.path.splitext(lm_name)[0],\n",
    "        \"act_bos_token\": \"[ACT]\",\n",
    "        \"resp_bos_token\": \"[RSP]\",\n",
    "        \"separate_vf\": False\n",
    "    },\n",
    "    \"ppo_config\": {\n",
    "        \"checkpoint_output_dpath\": os.path.join(ROOT_DPATH, \"experiments/ppo/outputs/checkpoints\"),\n",
    "        \"batch_size\": 128,\n",
    "        \"forward_batch_size\": 128,\n",
    "        \"minibatch_size\": 1,\n",
    "        \"ppo_epochs\": 4,\n",
    "        \"max_length\": 256,\n",
    "        \"lr\": 5.0e-6,\n",
    "        \"lr_linear_decay\": False,\n",
    "        \"gamma\":1.0,\n",
    "        \"lam\":0.95,\n",
    "        \"cliprange\": .2,\n",
    "        \"cliprange_value\":.2,\n",
    "        \"vf_coef\":.1,\n",
    "        \"target_kl\": 8,\n",
    "        \"init_kl_coef\":0.2,\n",
    "        \"horizon\":10000,\n",
    "        \"temperature\": 1.2\n",
    "    },\n",
    "    \"user_nlu_config\": {\n",
    "        \"nlu_name\": \"milu\",\n",
    "        \"nlu_model_name\": \"size1-sys\"\n",
    "    },\n",
    "    \"train_config\": {\n",
    "        \"random_seed\": 42,\n",
    "        \"total_iterations\": 50,\n",
    "        \"iterations_vf_pretrain\": 0,\n",
    "        \"reward_type\": \"F1\",\n",
    "        \"action_idf_weighted\": True,\n",
    "        \"checkpoint_save_dpath\": os.path.join(ROOT_DPATH, \"experiments/ppo/outputs/checkpoints\", \"model_save_test\"),\n",
    "    },\n",
    "    \"noise_config\": {\n",
    "        \"apply_noise\": True,\n",
    "        \"part\": \"val\",\n",
    "        \"side\": \"sys\",\n",
    "        \"noise_type\": \"background(20)\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"rl_nlg_test-noise\"\n",
    "run_id = \"model_save_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 10:39:10,448    INFO random_seed.py Set random seed to 42\n",
      "Using pad_token, but it is not set yet.\n",
      "/data/group1/z44383r/dev/rl-nlg/.venv/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:383z32kb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba12f78c96c4f809e0c56d58fe359f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">model_save_test</strong>: <a href=\"https://wandb.ai/ohashi56225/rl_nlg_test-noise/runs/383z32kb\" target=\"_blank\">https://wandb.ai/ohashi56225/rl_nlg_test-noise/runs/383z32kb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220504_103337-383z32kb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:383z32kb). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/group1/z44383r/dev/rl-nlg/experiments/ppo/wandb/run-20220504_103926-2wqhzhql</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ohashi56225/rl_nlg_test-noise/runs/2wqhzhql\" target=\"_blank\">model_save_test</a></strong> to <a href=\"https://wandb.ai/ohashi56225/rl_nlg_test-noise\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]2022-05-04 10:39:47,503    INFO     model.py Saving model checkpoint to /data/group1/z44383r/dev/rl-nlg/experiments/ppo/outputs/checkpoints/model_save_test/best.policy.0\n",
      "  2%|▏         | 1/50 [00:31<25:58, 31.81s/it]2022-05-04 10:40:21,641    INFO     model.py Saving model checkpoint to /data/group1/z44383r/dev/rl-nlg/experiments/ppo/outputs/checkpoints/model_save_test/best.policy.1\n",
      "  6%|▌         | 3/50 [01:26<22:02, 28.13s/it]2022-05-04 10:41:14,196    INFO     model.py Saving model checkpoint to /data/group1/z44383r/dev/rl-nlg/experiments/ppo/outputs/checkpoints/model_save_test/best.policy.3\n",
      " 12%|█▏        | 6/50 [02:45<19:32, 26.65s/it]2022-05-04 10:42:33,421    INFO     model.py Saving model checkpoint to /data/group1/z44383r/dev/rl-nlg/experiments/ppo/outputs/checkpoints/model_save_test/best.policy.6\n",
      " 18%|█▊        | 9/50 [04:03<17:49, 26.08s/it]2022-05-04 10:44:21,513    INFO     model.py Saving model checkpoint to /data/group1/z44383r/dev/rl-nlg/experiments/ppo/outputs/checkpoints/model_save_test/best.policy.9\n",
      " 24%|██▍       | 12/50 [05:50<19:08, 30.22s/it]2022-05-04 10:45:37,982    INFO     model.py Saving model checkpoint to /data/group1/z44383r/dev/rl-nlg/experiments/ppo/outputs/checkpoints/model_save_test/best.policy.12\n",
      " 32%|███▏      | 16/50 [07:56<16:51, 29.75s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_156/3353016731.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppo_updator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollouts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrollouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_vf_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppo_updator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollouts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrollouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m     \u001b[0mtiming\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time/optimization'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mtiming\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time/epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/group1/z44383r/dev/rl-nlg/ppo_utils/ppo_updator.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, rollouts, update_vf_only)\u001b[0m\n\u001b[1;32m    242\u001b[0m                     train_stats = self.train_minibatch(indices=mbatch.indices, logprobs=mbatch.logprobs, values=mbatch.values,\n\u001b[1;32m    243\u001b[0m                                                        \u001b[0mreturns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvantages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvantages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                                                        response_ids=mbatch.response_ids, model_input=mbatch.model_input)\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                     train_stats = self.train_minibatch_vf_only(indices=mbatch.indices, values=mbatch.values, returns=mbatch.returns,\n",
      "\u001b[0;32m/data/group1/z44383r/dev/rl-nlg/ppo_utils/ppo_updator.py\u001b[0m in \u001b[0;36mtrain_minibatch\u001b[0;34m(self, indices, logprobs, values, returns, advantages, response_ids, model_input)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mpg_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvf_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/group1/z44383r/dev/rl-nlg/.venv/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/group1/z44383r/dev/rl-nlg/.venv/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/group1/z44383r/dev/rl-nlg/.venv/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                     \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Adam does not support sparse gradients, please consider SparseAdam instead'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gpt2_config = config[\"gpt2_config\"]\n",
    "ppo_config = config[\"ppo_config\"]\n",
    "user_nlu_config = config[\"user_nlu_config\"]\n",
    "train_config = config[\"train_config\"]\n",
    "noise_config = config[\"noise_config\"]\n",
    "\n",
    "if train_config[\"random_seed\"] is not None:\n",
    "    set_seed(train_config[\"random_seed\"])\n",
    "\n",
    "tokenizer, policy_gpt2, value_gpt2, ref_policy_gpt2  = build_gpt2(gpt2_config)\n",
    "\n",
    "s_nlg = GPT2NLG(gpt2=policy_gpt2, tokenizer=tokenizer,\n",
    "                lm_task_type=gpt2_config[\"lm_task_type\"],\n",
    "                act_bos_token=gpt2_config[\"act_bos_token\"],\n",
    "                resp_bos_token=gpt2_config[\"resp_bos_token\"])\n",
    "s_ref_nlg = GPT2NLG(gpt2=ref_policy_gpt2, tokenizer=tokenizer,\n",
    "                    lm_task_type=gpt2_config[\"lm_task_type\"],\n",
    "                    act_bos_token=gpt2_config[\"act_bos_token\"],\n",
    "                    resp_bos_token=gpt2_config[\"resp_bos_token\"])\n",
    "\n",
    "ppo_updator = PPOUpdator(policy_model=policy_gpt2,\n",
    "                            value_model=value_gpt2,\n",
    "                            ref_policy_model=ref_policy_gpt2,\n",
    "                            total_iterations=train_config[\"total_iterations\"],\n",
    "                            ppo_config=ppo_config)\n",
    "\n",
    "speech_error_simulator = SpeechErrorSimulator.from_saved(part=noise_config[\"part\"],\n",
    "                                                            side=noise_config[\"side\"],\n",
    "                                                            noise_type=noise_config[\"noise_type\"])\n",
    "\n",
    "if user_nlu_config[\"nlu_name\"] == \"bert\":\n",
    "    from user_nlu.joint_bert.nlu import SimulatorBERTNLU\n",
    "    u_nlu = SimulatorBERTNLU(config_fname=f\"{user_nlu_config['nlu_model_name']}.json\")\n",
    "elif user_nlu_config[\"nlu_name\"] == \"milu\":\n",
    "    from user_nlu.milu.nlu import UserMILU\n",
    "    u_nlu = UserMILU(archive_dname=user_nlu_config[\"nlu_model_name\"])\n",
    "elif user_nlu_config[\"nlu_name\"] == \"svm\":\n",
    "    from convlab2.nlu.svm.multiwoz import SVMNLU\n",
    "    u_nlu = SVMNLU(mode=\"sys\")\n",
    "\n",
    "def run_nlu(system_response):\n",
    "    if noise_config[\"apply_noise\"]:\n",
    "        noised_system_response, _ = speech_error_simulator.apply_error(src_text=system_response)\n",
    "        pred_action = u_nlu.predict(noised_system_response)\n",
    "    else:\n",
    "        noised_system_response = \"\"\n",
    "        pred_action = u_nlu.predict(system_response)\n",
    "    return noised_system_response, pred_action\n",
    "\n",
    "multiwoz_data = MultiWOZData()\n",
    "ppo_train_data = PPOTrainData(multiwoz_data=multiwoz_data,\n",
    "                                parts_used=[\"train\"],\n",
    "                                batch_size=ppo_config[\"batch_size\"],\n",
    "                                shuffle=True, infinite=True)\n",
    "action_idf = ActionIDF(multiwoz_data=multiwoz_data,\n",
    "                        parts_used=[\"train\"]) # , \"val\"]\n",
    "\n",
    "compute_reward = ComputeReward(reward_type=train_config[\"reward_type\"],\n",
    "                                action_idf_weighted=train_config[\"action_idf_weighted\"])\n",
    "\n",
    "run = wandb.init(project=project_id,\n",
    "                    name=run_id,\n",
    "                    config=config)\n",
    "best_score = {'f1': float('-inf')}\n",
    "for iteration_id in tqdm(range(train_config[\"total_iterations\"])):\n",
    "    logs = dict()\n",
    "    table_log = defaultdict(list)\n",
    "    ref_table_columns = [\"ref/response\", \"ref/noised_response\", \"ref/f1\", \"ref/L_distance\"]\n",
    "    gen_table_columns = [\"gen/response\", \"gen/noised_response\", \"gen/f1\", \"gen/L_distance\"]\n",
    "    test_table_columns = [\"test/response\", \"test/noised_response\", \"test/f1\", \"test/L_distance\"]\n",
    "\n",
    "    env_log = defaultdict(list)\n",
    "    timing = dict()\n",
    "    t0 = time.time()\n",
    "\n",
    "    rollouts = Rollouts(batch_size=ppo_config[\"batch_size\"])\n",
    "\n",
    "    t = time.time()\n",
    "    batch = ppo_train_data.sample_batch()\n",
    "    ref_batch = []\n",
    "    gen_batch = []\n",
    "    test_batch = []\n",
    "    for fbi in range(0, ppo_config[\"batch_size\"], ppo_config[\"forward_batch_size\"]):\n",
    "        ref_batch += s_ref_nlg.batch_generate(batch=batch[fbi:fbi+ppo_config[\"forward_batch_size\"]],\n",
    "                                            max_length=ppo_config[\"max_length\"],\n",
    "                                            temperature=1.0,\n",
    "                                            do_sample=False)\n",
    "\n",
    "        gen_batch_ = s_nlg.batch_generate(batch=batch[fbi:fbi+ppo_config[\"forward_batch_size\"]],\n",
    "                                        max_length=ppo_config[\"max_length\"],\n",
    "                                        temperature=ppo_config[\"temperature\"],\n",
    "                                        do_sample=True)\n",
    "        gen_batch += gen_batch_\n",
    "        for gen in gen_batch_:\n",
    "            rollouts.insert_response(query_ids=gen['query_ids'].unsqueeze(0),\n",
    "                                    response_ids=gen['response_ids'].unsqueeze(0),\n",
    "                                    device=DEVICE)\n",
    "\n",
    "        test_batch += s_nlg.batch_generate(batch=batch[fbi:fbi+ppo_config[\"forward_batch_size\"]],\n",
    "                                        max_length=ppo_config[\"max_length\"],\n",
    "                                        temperature=1.0,\n",
    "                                        do_sample=False)\n",
    "        timing['time/response_generation'] = time.time()-t\n",
    "    timing['time/response_generation'] = time.time()-t\n",
    "\n",
    "    t = time.time()\n",
    "    for bi in range(ppo_config[\"batch_size\"]):\n",
    "        action = batch[bi][\"system_action\"]\n",
    "        # gt_response = batch[bi][\"system_response\"]\n",
    "        ref_response = ref_batch[bi][\"response_txt\"].replace(tokenizer.eos_token, \"\")\n",
    "        gen_response = gen_batch[bi][\"response_txt\"].replace(tokenizer.eos_token, \"\")\n",
    "        test_response = test_batch[bi][\"response_txt\"].replace(tokenizer.eos_token, \"\")\n",
    "\n",
    "        ref_noised_response, ref_pred_action = run_nlu(system_response=ref_response)\n",
    "        gen_noised_response, gen_pred_action = run_nlu(system_response=gen_response)\n",
    "        test_noised_response, test_pred_action = run_nlu(system_response=test_response)\n",
    "\n",
    "        ref_acc = da_accuracy(true_action=action, pred_action=ref_pred_action)\n",
    "        gen_acc = da_accuracy(true_action=action, pred_action=gen_pred_action)\n",
    "        test_acc = da_accuracy(true_action=action, pred_action=test_pred_action)\n",
    "\n",
    "        if ref_acc[\"tp_acts\"]:\n",
    "            ref_action_idfs = np.array([action_idf[gt_act] for gt_act in ref_acc[\"tp_acts\"]])\n",
    "        else:\n",
    "            ref_action_idfs = np.array([0.])\n",
    "        if gen_acc[\"tp_acts\"]:\n",
    "            gen_action_idfs =np.array([action_idf[gen_act] for gen_act in gen_acc[\"tp_acts\"]])\n",
    "        else:\n",
    "            gen_action_idfs = np.array([0.])\n",
    "\n",
    "        ref_tokens = ref_response.lower().split()\n",
    "        gen_tokens = gen_response.lower().split()\n",
    "        test_tokens = test_response.lower().split()\n",
    "\n",
    "        ref_gen_nld = nltk.edit_distance(ref_tokens, gen_tokens) / max(len(ref_tokens), len(gen_tokens))\n",
    "        ref_test_nld = nltk.edit_distance(ref_tokens, test_tokens) / max(len(ref_tokens), len(test_tokens))\n",
    "\n",
    "        reward = compute_reward(ref_acc=ref_acc, ref_action_idfs=ref_action_idfs, ref_tokens=ref_tokens,\n",
    "                                gen_acc=gen_acc, gen_action_idfs=gen_action_idfs, gen_tokens=gen_tokens,\n",
    "                                ref_gen_nld=ref_gen_nld)\n",
    "        rollouts.insert_reward(reward=torch.tensor([reward]), device=DEVICE)\n",
    "\n",
    "        table_log[\"ref/response\"].append(ref_response)\n",
    "        table_log[\"gen/response\"].append(gen_response)\n",
    "        table_log[\"test/response\"].append(test_response)\n",
    "        table_log[\"ref/noised_response\"].append(ref_noised_response)\n",
    "        table_log[\"gen/noised_response\"].append(gen_noised_response)\n",
    "        table_log[\"test/noised_response\"].append(test_noised_response)\n",
    "        table_log[\"ref/f1\"].append(ref_acc[\"f1\"])\n",
    "        table_log[\"gen/f1\"].append(gen_acc[\"f1\"])\n",
    "        table_log[\"test/f1\"].append(test_acc[\"f1\"])\n",
    "        table_log[\"ref/L_distance\"].append(0.)\n",
    "        table_log[\"gen/L_distance\"].append(ref_gen_nld)\n",
    "        table_log[\"test/L_distance\"].append(ref_test_nld)\n",
    "\n",
    "        env_log[\"reward\"].append(reward)\n",
    "        env_log[\"ref/f1\"].append(ref_acc[\"f1\"])\n",
    "        env_log[\"gen/f1\"].append(gen_acc[\"f1\"])\n",
    "        env_log[\"test/f1\"].append(test_acc[\"f1\"])\n",
    "        env_log[\"ref/acc\"].append(ref_acc[\"acc\"])\n",
    "        env_log[\"gen/acc\"].append(gen_acc[\"acc\"])\n",
    "        env_log[\"test/acc\"].append(test_acc[\"acc\"])\n",
    "        env_log[\"gen/length_increase\"].append(len(ref_tokens)-len(gen_tokens))\n",
    "        env_log[\"test/length_increase\"].append(len(ref_tokens)-len(test_tokens))\n",
    "    timing['time/response_evaluation'] = time.time()-t\n",
    "\n",
    "    env_result = {'env/reward_mean': np.mean(env_log['reward']).item(),\n",
    "                    'env/reward_std': np.std(env_log['reward']).item(),\n",
    "                    'env/reward_dist': env_log['reward'],\n",
    "                    'env/gen_f1': np.mean(env_log[\"gen/f1\"]).item(),\n",
    "                    'env/test_f1': np.mean(env_log[\"test/f1\"]).item(),\n",
    "                    'env/ref_f1': np.mean(env_log[\"ref/f1\"]).item(),\n",
    "                    'env/gen_acc': np.mean(env_log[\"gen/acc\"]).item(),\n",
    "                    'env/test_acc': np.mean(env_log[\"test/acc\"]).item(),\n",
    "                    'env/ref_acc': np.mean(env_log[\"ref/acc\"]).item(),\n",
    "                    'env/length_increase': np.mean(env_log[\"test/length_increase\"]).item()}\n",
    "\n",
    "    if best_score[\"f1\"] < env_result[\"env/test_f1\"]:\n",
    "        t = time.time()\n",
    "        best_score[\"f1\"] = env_result[\"env/test_f1\"]\n",
    "        policy_gpt2.save_checkpoint(tokenizer=tokenizer,\n",
    "                                    output_dpath=train_config[\"checkpoint_save_dpath\"],\n",
    "                                    prefix=f\"policy.{iteration_id}\",\n",
    "                                    eval_results=env_result)\n",
    "        timing['time/checkpoint_save'] = time.time()-t\n",
    "    \n",
    "    t = time.time()\n",
    "    if iteration_id < train_config[\"iterations_vf_pretrain\"]:\n",
    "        stats = ppo_updator.step(rollouts=rollouts, update_vf_only=True)\n",
    "    else:\n",
    "        stats = ppo_updator.step(rollouts=rollouts)\n",
    "    timing['time/optimization'] = time.time()-t\n",
    "    timing['time/epoch'] = time.time()-t0\n",
    "\n",
    "    ref_table_rows = [list(row) for row in zip(*(table_log[col] for col in ref_table_columns))]\n",
    "    gen_table_rows = [list(row) for row in zip(*(table_log[col] for col in gen_table_columns))]\n",
    "    test_table_rows = [list(row) for row in zip(*(table_log[col] for col in test_table_columns))]\n",
    "    wandb.log({**env_result,\n",
    "                **stats,\n",
    "                **timing,\n",
    "                'table/ref': wandb.Table(columns=ref_table_columns, rows=ref_table_rows),\n",
    "                'table/gen': wandb.Table(columns=gen_table_columns, rows=gen_table_rows),\n",
    "                'table/test': wandb.Table(columns=test_table_columns, rows=test_table_rows)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4cbe8206254ccc8bb913dff005ec5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='2.154 MB of 2.154 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>env/gen_acc</td><td>▁▆▄▄▂▇▃▅▄▅▅▃█▆▆▆</td></tr><tr><td>env/gen_f1</td><td>▁▆▄▄▂▇▃▅▃▆▅▃█▆▆▆</td></tr><tr><td>env/length_increase</td><td>▃▅▆▆▅▄▃▃▁▇▇█▅▅█▆</td></tr><tr><td>env/ref_acc</td><td>▄█▄▃▆▄▄▂▁▇▁▃▃▅▆▆</td></tr><tr><td>env/ref_f1</td><td>▄█▅▃▇▄▅▁▂█▁▃▃▆▇▆</td></tr><tr><td>env/reward_mean</td><td>▁▄▄▂▁▅▂▅▂▅▅▃█▅▆▅</td></tr><tr><td>env/reward_std</td><td>▆▄▇▃▇▆▂▇▇▁▇▅▆▂█▂</td></tr><tr><td>env/test_acc</td><td>▃▆▅▇▅▆▇▄▂▇▁▂█▃▇▇</td></tr><tr><td>env/test_f1</td><td>▃▆▅▆▆▆█▃▃█▁▂█▄█▇</td></tr><tr><td>objective/entropy</td><td>█▅▆▄█▃▅▄▅▆▃▃▁▄▃▃</td></tr><tr><td>objective/kl</td><td>▁▂▂▂▃▄▄▃▅█▅▆▇▇█▆</td></tr><tr><td>objective/kl_coef</td><td>██▇▇▆▆▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>ppo/loss/policy</td><td>▅▅▂█▆▇▄▇▃▁▄▅▂▇▄▇</td></tr><tr><td>ppo/loss/total</td><td>██▅▇▅▆▃▅▂▁▃▃▂▄▂▄</td></tr><tr><td>ppo/loss/value</td><td>██▆▄▃▄▂▃▂▂▂▂▂▁▂▁</td></tr><tr><td>ppo/mean_non_score_reward</td><td>█▇▆▇▆▅▅▅▄▁▃▃▂▂▁▃</td></tr><tr><td>ppo/policy/advantages_mean</td><td>▄▄▆▁▃▃▅▂▆█▅▄▇▃▆▃</td></tr><tr><td>ppo/policy/approxkl</td><td>▁▃▂▄▄█▇▄▄▆▃▇▆▇▆▄</td></tr><tr><td>ppo/policy/clipfrac</td><td>▁▂▅██▆▆▄▅▄▂▅▃▃▂▁</td></tr><tr><td>ppo/policy/entropy</td><td>█▆▇▆▆▅▆▅▅▄▃▃▂▃▂▁</td></tr><tr><td>ppo/policy/policykl</td><td>█▄▆▃▄▁▃▅▆▃▅▄▅▃▃▆</td></tr><tr><td>ppo/returns/mean</td><td>▁▃▃▄▄▅▅▆▆▆▇▇█▇█▇</td></tr><tr><td>ppo/returns/var</td><td>██▆▃▄▄▂▃▂▂▂▁▂▁▂▁</td></tr><tr><td>ppo/val/clipfrac</td><td>██▇▅▄▅▃▃▂▂▂▁▂▁▁▁</td></tr><tr><td>ppo/val/error</td><td>██▆▄▃▄▂▃▂▂▂▂▂▁▂▁</td></tr><tr><td>ppo/val/mean</td><td>▁▂▃▃▄▄▅▆▆▆▇▇▇███</td></tr><tr><td>ppo/val/var</td><td>█▆▅▄▃▃▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>ppo/val/var_explained</td><td>▃▃▄▁▆▅▄▅▅█▆▆▆▇▇█</td></tr><tr><td>ppo/val/vpred</td><td>▁▂▃▄▄▅▅▆▆▇▇▇████</td></tr><tr><td>time/checkpoint_save</td><td>█▁▁▁▂▁</td></tr><tr><td>time/epoch</td><td>▂▂▁▁▁▁▁▁▁█▁▁▁▁▁▁</td></tr><tr><td>time/optimization</td><td>█▄▄▁▃▂▁▄▂▄▂▁▂▂▁▃</td></tr><tr><td>time/ppo/calc_stats</td><td>█▃▂▂▄▃▃▄▆▆▃▁▅▄▂▃</td></tr><tr><td>time/ppo/forward_pass</td><td>█▆▆▂▃▂▁▇▆▇▂▃▄▃▁▃</td></tr><tr><td>time/ppo/optimize_step</td><td>█▄▄▁▄▂▁▃▁▄▃▁▁▂▂▃</td></tr><tr><td>time/ppo/total</td><td>█▄▄▁▃▂▁▄▂▄▂▁▂▂▁▃</td></tr><tr><td>time/response_evaluation</td><td>▁▂▂▂▂▁▁▃▂█▁▁▁▁▁▂</td></tr><tr><td>time/response_generation</td><td>▁▂▁▁▁▁▁▁▁█▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>env/gen_acc</td><td>0.48924</td></tr><tr><td>env/gen_f1</td><td>0.56448</td></tr><tr><td>env/length_increase</td><td>0.49219</td></tr><tr><td>env/ref_acc</td><td>0.61652</td></tr><tr><td>env/ref_f1</td><td>0.68849</td></tr><tr><td>env/reward_mean</td><td>1.74817</td></tr><tr><td>env/reward_std</td><td>1.19398</td></tr><tr><td>env/test_acc</td><td>0.62072</td></tr><tr><td>env/test_f1</td><td>0.69301</td></tr><tr><td>objective/entropy</td><td>25.23724</td></tr><tr><td>objective/kl</td><td>1.54491</td></tr><tr><td>objective/kl_coef</td><td>0.19246</td></tr><tr><td>ppo/loss/policy</td><td>-0.07712</td></tr><tr><td>ppo/loss/total</td><td>-0.04579</td></tr><tr><td>ppo/loss/value</td><td>0.31323</td></tr><tr><td>ppo/mean_non_score_reward</td><td>-0.29733</td></tr><tr><td>ppo/policy/advantages_mean</td><td>0.03358</td></tr><tr><td>ppo/policy/approxkl</td><td>0.20063</td></tr><tr><td>ppo/policy/clipfrac</td><td>0.21512</td></tr><tr><td>ppo/policy/entropy</td><td>0.72529</td></tr><tr><td>ppo/policy/policykl</td><td>-0.06236</td></tr><tr><td>ppo/returns/mean</td><td>1.62667</td></tr><tr><td>ppo/returns/var</td><td>0.07714</td></tr><tr><td>ppo/val/clipfrac</td><td>0.02905</td></tr><tr><td>ppo/val/error</td><td>0.62329</td></tr><tr><td>ppo/val/mean</td><td>1.64609</td></tr><tr><td>ppo/val/var</td><td>0.12583</td></tr><tr><td>ppo/val/var_explained</td><td>-7.07985</td></tr><tr><td>ppo/val/vpred</td><td>1.63847</td></tr><tr><td>time/checkpoint_save</td><td>0.77048</td></tr><tr><td>time/epoch</td><td>25.1494</td></tr><tr><td>time/optimization</td><td>16.36846</td></tr><tr><td>time/ppo/calc_stats</td><td>0.02977</td></tr><tr><td>time/ppo/forward_pass</td><td>1.85702</td></tr><tr><td>time/ppo/optimize_step</td><td>14.47535</td></tr><tr><td>time/ppo/total</td><td>16.36222</td></tr><tr><td>time/response_evaluation</td><td>5.80986</td></tr><tr><td>time/response_generation</td><td>2.96904</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">model_save_test</strong>: <a href=\"https://wandb.ai/ohashi56225/rl_nlg_test-noise/runs/2wqhzhql\" target=\"_blank\">https://wandb.ai/ohashi56225/rl_nlg_test-noise/runs/2wqhzhql</a><br/>Synced 5 W&B file(s), 48 media file(s), 48 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220504_103926-2wqhzhql/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
